#!/usr/bin/env python
# coding: utf-8

# Домашняя работа к Уроку Урок 7. Многомерный статистический анализ. Линейная регрессия

# In[1]:


import numpy as np
import pandas as pd

from scipy.stats import norm
from math import sqrt


# 1. Даны значения величины заработной платы заемщиков банка (zp) и значения их поведенческого кредитного скоринга (ks):
# zp = [35, 45, 190, 200, 40, 70, 54, 150, 120, 110],
# 
# ks = [401, 574, 874, 919, 459, 739, 653, 902, 746, 832].
# 
# Используя математические операции, посчитать коэффициенты линейной регрессии, приняв за X заработную плату (то есть, zp - признак), а за y - значения скорингового балла (то есть, ks - целевая переменная).
# 
# Произвести расчет как с использованием intercept, так и без.

# In[2]:


x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110]) #заработная плата заемщиков
y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832]) #поведенческий кредитный скоринг
n = len(x)


# In[3]:


b = (np.mean(x*y) - np.mean(x) * np.mean(y)) / (np.mean(x**2) - np.mean(x)**2)
a = np.mean(y) - b * np.mean(x)
lr = a + b * x

print(f'Коэффициент линейной регрессии b - {b},\nКоэффициент линейной регрессии a - {a},\nЛинейная регрессия - {lr}')


# In[4]:


b = (n*(np.sum(x*y)) - (np.sum(x)*np.sum(y))) / (n*np.sum(x**2) - np.sum(x)**2)
a = np.mean(y) - (b * np.mean(x))
lr = a + b * x

print(f'Коэффициент линейной регрессии b - {b},\nКоэффициент линейной регрессии a - {a},\nЛинейная регрессия - {lr}')


# Без intercept:

# In[5]:


y = y.reshape(10,1)
x = np.hstack([np.ones((10,1)),x.reshape(10,1)])
b = np.linalg.inv(x.T@x)@x.T@y

print(f'Коэффициенты линейной регрессии a, b - {b}')


# Без intercept:

# In[6]:


x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110]) #заработная плата заемщиков
y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832]) #поведенческий кредитный скоринг
y = y.reshape(10,1)
x = x.reshape(10,1)
b = np.dot(np.linalg.inv(np.dot(x.T,x)),x.T @ y)
print(f'Коэффициенты линейной регрессии b - {b}')


# 2. Посчитать коэффициент линейной регрессии при заработной плате (zp), используя градиентный спуск (без intercept).

# In[7]:


x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110]) #заработная плата заемщиков
y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832]) #поведенческий кредитный скоринг
n = len(x)
α = 1e-6
w1 = 0.1

def mse(w1=w1, y=y, x=x, n=n):
    return np.sum((w1 * x - y)**2) / n

for i in range (10000):
    w1 -= α * (2 / n) * np.sum((w1 * x - y) * x)
    if i % 1000 == 0:
        print('Iteration: {i}, w1 = {w1}, mse = {mse}'.format(i=i, w1=w1, mse=mse(w1)))


# *3. Произвести вычисления как в пункте 2, но с вычислением intercept.
# Учесть, что изменение коэффициентов должно производиться на каждом шаге одновременно (то есть изменение одного коэффициента не должно влиять на изменение другого во время одной итерации).

# In[8]:


x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110]) #заработная плата заемщиков
y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832]) #поведенческий кредитный скоринг
n = len(x)
α = 5e-5
w0 = 0.1
w1 = 0.1

def mse(w0=w0, w1=w1, y = y, x = x, n = n):
    return sum((w0 + w1 * x - y) ** 2) / n

for i in range(1000000):   
    w0 -= α * (2 / n) * np.sum(w0 + w1 * x - y)
    w1 -= α * (2 / n) * np.sum((w0 + w1 * x - y) * x)
    if (i + 1) % 100000 == 0 :
        print('Iteration: {i}, w0 = {w0}, w1 = {w1}, mse = {mse}'.format(i=i, w0=w0, w1=w1, mse=mse(w1)))
print(f"Линейная регрессия = {round(w0,4)} + {round(w1,4)}x")


# In[9]:


α, w0, w1, eps = 5e-5, 0.1, 0.1, 1e-10
w0_, w1_ = w0 + 2 * eps, w1 + 2 * eps
stop, i = 1000000, 0
while i <= stop and abs(w0 - w0_) * abs(w1 - w1_) > eps**2:
    w0_, w1_, i = w0, w1, i + 1
    w1 -= α * (2/n) * np.sum(((w0 + w1 * x) - y) * x)
    w0 -= α * (2/n) * np.sum((w0 + w1 * x) - y)
print(f'Линейная регрессия y = {round(w0, 4)} + {round(w1, 4)}x,\n{i} - итераций')


# In[ ]:




